{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8158768,"sourceType":"datasetVersion","datasetId":4805325}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport nltk\nfrom nltk.corpus import stopwords\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:54:53.541531Z","iopub.execute_input":"2024-07-01T15:54:53.542567Z","iopub.status.idle":"2024-07-01T15:54:59.920913Z","shell.execute_reply.started":"2024-07-01T15:54:53.542521Z","shell.execute_reply":"2024-07-01T15:54:59.919939Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')\n\n# Load English stopwords\nstop_words = set(stopwords.words('english'))\n\n# Load your data\ndf = pd.read_csv('/kaggle/input/assign4-nlp/train.csv')\n\ndef preprocess_text(text):\n    text = text.lower()  # Lowercase the text\n    # Remove punctuations\n    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n    # Adding start of sequence and end of sequence tokens\n    return f'<sos> {text} <eos>'\n\n# Apply preprocessing\ndf['Processed'] = df['Description'].apply(preprocess_text)\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:54:59.922729Z","iopub.execute_input":"2024-07-01T15:54:59.923540Z","iopub.status.idle":"2024-07-01T15:55:04.971635Z","shell.execute_reply.started":"2024-07-01T15:54:59.923503Z","shell.execute_reply":"2024-07-01T15:55:04.970597Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n   Class Index                                        Description  \\\n0            3  Reuters - Short-sellers, Wall Street's dwindli...   \n1            3  Reuters - Private investment firm Carlyle Grou...   \n2            3  Reuters - Soaring crude prices plus worries\\ab...   \n3            3  Reuters - Authorities have halted oil export\\f...   \n4            3  AFP - Tearaway world oil prices, toppling reco...   \n\n                                           Processed  \n0  <sos> reuters shortsellers wall streets dwindl...  \n1  <sos> reuters private investment firm carlyle ...  \n2  <sos> reuters soaring crude prices plus worrie...  \n3  <sos> reuters authorities halted oil exportflo...  \n4  <sos> afp tearaway world oil prices toppling r...  \n","output_type":"stream"}]},{"cell_type":"code","source":"df['Tokens'] = df['Processed'].apply(lambda text: text.split())\nvocab = set(token for tokens in df['Tokens'] for token in tokens)\ntoken_to_index = {token: idx + 1 for idx, token in enumerate(vocab)}  # +1 for zero padding\ntoken_to_index['<pad>'] = 0  # Padding token\ntoken_to_index['<unk>'] = len(token_to_index)+1","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:55:04.973018Z","iopub.execute_input":"2024-07-01T15:55:04.973336Z","iopub.status.idle":"2024-07-01T15:55:05.939171Z","shell.execute_reply.started":"2024-07-01T15:55:04.973308Z","shell.execute_reply":"2024-07-01T15:55:05.938373Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load_glove_embeddings(path, embedding_dim=100):\n    embeddings_dict = {}\n    with open(path, 'r', encoding='utf-8') as file:\n        for line in file:\n            values = line.split()\n            word = values[0]\n            vector = np.asarray(values[1:], dtype='float32')\n            embeddings_dict[word] = vector\n    return embeddings_dict\n\n\nglove_embeddings = load_glove_embeddings('/kaggle/input/assign4-nlp/glove.6B.100d.txt')","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:55:05.941075Z","iopub.execute_input":"2024-07-01T15:55:05.941360Z","iopub.status.idle":"2024-07-01T15:55:18.583423Z","shell.execute_reply.started":"2024-07-01T15:55:05.941336Z","shell.execute_reply":"2024-07-01T15:55:18.582365Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, df, glove_embeddings, token_to_index, embedding_dim=100):\n        self.sentences = df['Tokens'].tolist()\n        self.glove_embeddings = glove_embeddings\n        self.token_to_index = token_to_index\n        self.embedding_dim = embedding_dim\n        self.unk_idx = token_to_index['<unk>']  # Use this for unknown tokens\n    \n    def __len__(self):\n        return len(self.sentences)\n    \n    def __getitem__(self, idx):\n        tokens = self.sentences[idx]\n        # Convert tokens to indices\n        indices = [self.token_to_index.get(token, self.unk_idx) for token in tokens]\n        # Create input and target sequences\n        input_indices = indices\n        target_indices = indices[1:] + [self.token_to_index['<eos>']]  # Shift by one and append <eos>\n        \n        # Convert indices to embeddings\n        input_embeddings = [self.glove_embeddings.get(token, np.zeros(self.embedding_dim)) for token in tokens]\n        \n        return torch.tensor(input_embeddings, dtype=torch.float32), torch.tensor(target_indices, dtype=torch.long)\n\n    \ndef collate_batch(batch):\n    inputs, targets = zip(*batch)\n    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=0.0)\n    padded_targets = pad_sequence(targets, batch_first=True, padding_value=token_to_index['<pad>'])\n    return padded_inputs, padded_targets\n\n# Create Dataset and DataLoader instances\ndataset = TextDataset(df, glove_embeddings,token_to_index)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True,collate_fn=collate_batch)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:55:18.585382Z","iopub.execute_input":"2024-07-01T15:55:18.585745Z","iopub.status.idle":"2024-07-01T15:55:18.608257Z","shell.execute_reply.started":"2024-07-01T15:55:18.585713Z","shell.execute_reply":"2024-07-01T15:55:18.607123Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class ELMoLanguageModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, setting=1):\n        super(ELMoLanguageModel, self).__init__()\n        self.setting = setting\n        self.forward_lstm1 = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n        self.forward_lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n        self.backward_lstm1 = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n        self.backward_lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n        self.forward_pred = nn.Linear(hidden_dim, vocab_size)\n        self.backward_pred = nn.Linear(hidden_dim, vocab_size)\n\n        if setting == 1:\n            self.gamma = nn.Parameter(torch.ones(3))\n        elif setting == 2:\n            self.gamma = torch.rand(3, requires_grad=False)\n        elif setting == 3:\n            self.combiner = nn.Sequential(\n                nn.Linear(hidden_dim * 6, hidden_dim * 2),\n                nn.ReLU(),\n                nn.Linear(hidden_dim * 2, hidden_dim*2)\n            )\n            self.gamma = nn.Parameter(torch.ones(3))  \n\n    def forward(self, x):\n        forward_out1, _ = self.forward_lstm1(x)\n        forward_out2, _ = self.forward_lstm2(forward_out1)\n        reversed_embeddings = torch.flip(x, [1])\n        backward_out1, _ = self.backward_lstm1(reversed_embeddings)\n        backward_out2, _ = self.backward_lstm2(backward_out1)\n\n        if self.setting in [1, 2]:\n            combined_embeddings = self.gamma[0] * x + self.gamma[1] * torch.cat((forward_out1, backward_out1), dim=-1) + self.gamma[2] * torch.cat((forward_out2, backward_out2), dim=-1)\n        elif self.setting == 3:\n            combined_embeddings = self.combiner(torch.cat((x, forward_out1, backward_out1, forward_out2, backward_out2), dim=-1))\n\n        forward_predictions = self.forward_pred(forward_out2)\n        backward_predictions = self.backward_pred(torch.flip(backward_out2, [1]))\n        return forward_predictions, backward_predictions, combined_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:55:18.609939Z","iopub.execute_input":"2024-07-01T15:55:18.610268Z","iopub.status.idle":"2024-07-01T15:55:18.629001Z","shell.execute_reply.started":"2024-07-01T15:55:18.610240Z","shell.execute_reply":"2024-07-01T15:55:18.627944Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(token_to_index) \nmodel_setting_1 = ELMoLanguageModel(vocab_size=vocab_size, embedding_dim=100, hidden_dim=50, setting=1).to(\"cuda\")\nmodel_setting_2 = ELMoLanguageModel(vocab_size=vocab_size, embedding_dim=100, hidden_dim=50, setting=2).to(\"cuda\")\nmodel_setting_3 = ELMoLanguageModel(vocab_size=vocab_size, embedding_dim=100, hidden_dim=50, setting=3).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:55:18.632190Z","iopub.execute_input":"2024-07-01T15:55:18.632527Z","iopub.status.idle":"2024-07-01T15:55:19.291610Z","shell.execute_reply.started":"2024-07-01T15:55:18.632504Z","shell.execute_reply":"2024-07-01T15:55:19.290618Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# First Model","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\n\noptimizer = optim.Adam(model_setting_1.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n    num_batches = 0\n    \n    for inputs, targets in tqdm(dataloader):\n        inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n        optimizer.zero_grad()\n        \n        forward_pred, backward_pred, _ = model_setting_1(inputs) ## adjust model\n        \n        loss_f = criterion(forward_pred.transpose(1, 2), targets)\n        loss_b = criterion(backward_pred.transpose(1, 2), targets)\n        loss = loss_f + loss_b\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n    \n    average_loss = total_loss / num_batches\n    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:55:19.293094Z","iopub.execute_input":"2024-07-01T15:55:19.293915Z","iopub.status.idle":"2024-07-01T17:52:33.961552Z","shell.execute_reply.started":"2024-07-01T15:55:19.293876Z","shell.execute_reply":"2024-07-01T17:52:33.960371Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"  0%|          | 0/7500 [00:00<?, ?it/s]/tmp/ipykernel_34/1560757017.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:261.)\n  return torch.tensor(input_embeddings, dtype=torch.float32), torch.tensor(target_indices, dtype=torch.long)\n100%|██████████| 7500/7500 [11:38<00:00, 10.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Average Loss: 10.2769\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:34<00:00, 10.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Average Loss: 8.2431\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:36<00:00, 10.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Average Loss: 6.9575\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:46<00:00, 10.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Average Loss: 6.1661\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:47<00:00, 10.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Average Loss: 5.6903\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:47<00:00, 10.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Average Loss: 5.3772\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:45<00:00, 10.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Average Loss: 5.1479\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:41<00:00, 10.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Average Loss: 4.9785\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:46<00:00, 10.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Average Loss: 4.8303\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:45<00:00, 10.63it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Average Loss: 4.7269\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pickle\n\n# Save the model's state dictionary\ntorch.save(model_setting_1.state_dict(), 'elmo_model_1_state_dict.pth')\n\n# Save the token_to_index dictionary\nwith open('token_to_index.pkl', 'wb') as f:\n    pickle.dump(token_to_index, f)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T17:52:33.963225Z","iopub.execute_input":"2024-07-01T17:52:33.964085Z","iopub.status.idle":"2024-07-01T17:52:34.094932Z","shell.execute_reply.started":"2024-07-01T17:52:33.964044Z","shell.execute_reply":"2024-07-01T17:52:34.093832Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Second Model","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\n\noptimizer = optim.Adam(model_setting_2.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n    num_batches = 0\n    \n    for inputs, targets in tqdm(dataloader):\n        inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n        optimizer.zero_grad()\n        \n        forward_pred, backward_pred, _ = model_setting_2(inputs) ## adjust model\n        \n        loss_f = criterion(forward_pred.transpose(1, 2), targets)\n        loss_b = criterion(backward_pred.transpose(1, 2), targets)\n        loss = loss_f + loss_b\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n    \n    average_loss = total_loss / num_batches\n    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T17:52:34.099063Z","iopub.execute_input":"2024-07-01T17:52:34.099507Z","iopub.status.idle":"2024-07-01T19:49:59.829013Z","shell.execute_reply.started":"2024-07-01T17:52:34.099467Z","shell.execute_reply":"2024-07-01T19:49:59.827897Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 7500/7500 [11:44<00:00, 10.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Average Loss: 10.7086\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:48<00:00, 10.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Average Loss: 8.5907\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:40<00:00, 10.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Average Loss: 7.3084\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:44<00:00, 10.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Average Loss: 6.5910\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:46<00:00, 10.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Average Loss: 6.1349\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:44<00:00, 10.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Average Loss: 5.7191\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:41<00:00, 10.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Average Loss: 5.4156\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:42<00:00, 10.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Average Loss: 5.2099\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:48<00:00, 10.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Average Loss: 5.0348\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:45<00:00, 10.64it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Average Loss: 4.9027\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pickle\n\n# Save the model's state dictionary\ntorch.save(model_setting_2.state_dict(), 'elmo_model_2_state_dict.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-01T19:49:59.830506Z","iopub.execute_input":"2024-07-01T19:49:59.831000Z","iopub.status.idle":"2024-07-01T19:49:59.903811Z","shell.execute_reply.started":"2024-07-01T19:49:59.830962Z","shell.execute_reply":"2024-07-01T19:49:59.902873Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Third Model","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\n\noptimizer = optim.Adam(model_setting_3.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n    num_batches = 0\n    \n    for inputs, targets in tqdm(dataloader):\n        inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n        optimizer.zero_grad()\n        \n        forward_pred, backward_pred, _ = model_setting_3(inputs) ## adjust model\n        \n        loss_f = criterion(forward_pred.transpose(1, 2), targets)\n        loss_b = criterion(backward_pred.transpose(1, 2), targets)\n        loss = loss_f + loss_b\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n    \n    average_loss = total_loss / num_batches\n    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T19:49:59.905080Z","iopub.execute_input":"2024-07-01T19:49:59.905381Z","iopub.status.idle":"2024-07-01T21:47:16.989511Z","shell.execute_reply.started":"2024-07-01T19:49:59.905354Z","shell.execute_reply":"2024-07-01T21:47:16.988479Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 7500/7500 [11:49<00:00, 10.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Average Loss: 10.6031\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:50<00:00, 10.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Average Loss: 8.4765\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:48<00:00, 10.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Average Loss: 7.5384\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:48<00:00, 10.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Average Loss: 6.7869\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:47<00:00, 10.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Average Loss: 6.2741\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:41<00:00, 10.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Average Loss: 5.9229\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:40<00:00, 10.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Average Loss: 5.5972\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:41<00:00, 10.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Average Loss: 5.3371\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:37<00:00, 10.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Average Loss: 5.1263\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7500/7500 [11:31<00:00, 10.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Average Loss: 4.9684\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pickle\n\n# Save the model's state dictionary\ntorch.save(model_setting_3.state_dict(), 'elmo_model_3_state_dict.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-01T21:47:16.990851Z","iopub.execute_input":"2024-07-01T21:47:16.991134Z","iopub.status.idle":"2024-07-01T21:47:17.072749Z","shell.execute_reply.started":"2024-07-01T21:47:16.991109Z","shell.execute_reply":"2024-07-01T21:47:17.071906Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}